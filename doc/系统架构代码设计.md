#### 系统架构设计

> 前言：此系统目前设计的是单机情况下，待系统代码全部写完后在出分布式情况下的设计，并做出相应的优化，目前单机系统下暂时不考虑redis，es等中简介宕机、断电等特殊情况(分布式系统的话就用集群、同步数据)。当然并不是作者不会分布式技术而是成熟的系统需要一步一步的优化(等这个系统完善后在出分布式版本)，上去就设计分布式不仅会增加工作量而且还会延期项目的交付，并不是一下就可以非常完美的，这里提醒各位同学没有谁的代码可以一步到位，都是经过不断优化的，欲速则不达

##### 1.支持高并发，解决高并发情况下的数据查询和写入的问题(查询藏品信息和超卖问题)

在数据查询的时候考虑到缓存和数据库进行双写、读写不一致，缓存穿透击穿等问题，详情看下方的 开发应考虑因素

##### 2.对api进行削峰填谷，优化api请求速度

![rabbitmq指定数据拉取请求](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/rabbitmq%E6%8C%87%E5%AE%9A%E6%95%B0%E6%8D%AE%E6%8B%89%E5%8F%96%E8%AF%B7%E6%B1%82.png)

###### 为什么要削峰？

问：不是给我增加耗时吗？本来人家下订单本来可以直接进行操作数据库进行处理，你加了一个mq发送接受，不应该是增加了接口耗时吗？

答：如果在并发量不大的情况下，确实没问题，但是在高并发情况下如果不进行削锋很容易导致mysql连接或操作次数过多导致mysql宕机，你觉得是在并发量多的情况下老板是想让用户多等那不到`几毫秒`的时间还是说让mysql直接宕机？通常情况下，mq发送操作耗时几乎可以忽略不记，并且接受到信息进行执行也是异步执行的，整体来说会优化api请求速度

流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。

应用场景：

1.秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。	

2.任何需要异步的操作，可以优化接口相应速度

![异步注册操作](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/%E5%BC%82%E6%AD%A5%E6%B3%A8%E5%86%8C%E6%93%8D%E4%BD%9C.png)

##### 3.使用ES优化藏品搜索

​	ES的基本搜索使用例如关键词搜索，高亮搜索等

##### 4.使用Redis缓存用户信息和热数据减少数据库压力

​	因为用户信息是固定的很少发生变化可以直接使用redis进行缓存避免每次都查询mysql数据库，同时使用redis进行缓存热数据，并考虑冷门藏品爆款等问题。

##### 5.对日志进行统一打印输出到文件中，使用异步线程优化日志

​	顾名思义使用log4j2优化日志输出至指定的文件夹中，日级别的分割日志方便管理，若大型系统还可以根据这个输出的日志进行做一个日志管理可视化查看或统计，更模块话的系统

---

##### 开发应考虑因素 -- 后面给出解决办法，若有更多问题或更好解法欢迎讨论

压力因素：查询数据应先讲热数据保存至redis中，冷数据优先查询mysql后查询区块链中存贮
数据因素：

  1. 缓存击穿问题，大量藏品在同一时间同时失效，大量请求穿过redis打到mysql中
     解决办法：添加redis缓存时增加随机数，防止缓存同一事件失效

  2. 缓存穿透问题，商品已经删了，但是大量的请求还是重复请求了redis然后redis查不到在查询mysql，导致数据库宕机，
     解决办法：可以设置空缓存，就是查询redis查不到，查询mysql差不到直接设置几分钟空缓存，下一个请求进来时只能查到redis中空值，不会导致数据库压力很大

  3. 突发性热点`缓存重建`导致系统压力暴增问题，比如十几万人同时点开这个冷门商品，刚开始同一时间可能会查询几万次mysql，而且有同时设置redis缓存 。解决办法使用synchronized、使用DCL(单例模式的双层检测锁) 也就是会从新查询一次redis数据库，不会导致在极端情况下，请求在等待synchronized排队后还的都重复查询mysql达不到设置缓存的效果，这里的synchronized不能锁this，不然比如说查2个商品的话，那就得都在这排队查询，很影响性能，比如多台机器每个机器都需要重构一次（这个影响很小），还有个问题就是如果这2个商品并没任何关系，所以不能锁this，比如锁商品id，但是如果是多台机器部署的后端还需要考虑很多问题,但是建议还是这里使用分布式redis锁，没想到吧！查询也需要使用redis锁不然也会导致mysql被打掉。

  4. 缓存与数据库双写不一致问题（缓存和数据库读写不一致也同理）：存在于在更新商品信息的时候正好有线程在查询这个商品，会导致缓存存贮的是旧信息
     解决方法：延时双删、设置缓存过期时间等，
     还有个`万全的`方法是继续使用分布式锁，在线程3查询数据库之前加锁和在线程2写入数据库之前加一把锁，这样就可以解决了
     问题：加那么多锁有性能问题，可以使用读写锁（读多写少）做性能优化，更新数据用写锁
     查询数据用读锁，这样读锁可以并发执行，而写锁会排队等待，这样可以优化性能
     	

应考虑mysql和区块链中数据一致性问题，例如数据更新时需要先更新区块链中数据在更新mysql中数据，考虑

业务因素：rabbitmq幂等性问题，比如创建一个mysql的流水表，在发送队列消息的时候插入到流水表中，下次插入时需要查询表中是否有记录，无记录才能插入，可以使用redis做记录不用mysql也可以

开发统一：数据库命名一律使用小写加下划线，禁止使用驼峰（linux和windows不同中有影响，详细请自查）

#### 代码优化更新记录

​	使用validation自定义等注解优化传入参数校验

#### 存贮设计

在mysql中：存贮用户基本信息

user_info：存贮用户基本信息 

```
*主键 id
*字段 用户地址 address
*字段 用户名 username
*字段 用户密码 password
```

user_detal：是否实名认证、认证信息

```
*主键 id
*字段 副主键和user_info对应的 外键
*字段 用户地址 address
*字段 身份证 cardid
*字段 手机号 phone_number
```

sell_info : 存贮发售信息

```
 * 主键 id
 * 字段 数字藏品 hash
 * 字段 发行量 amount
 * 字段 剩余数量 remain
 * 字段 数字藏品作者 auther
 * 字段 发售状态 status  # 1 为正常 ，  0 为闭售
```

owner_ship: 存贮当前用户的藏品所属权

```
 * 主键 id
 * 字段 用户地址 address
 * 字段 数字hash hash
 * 字段 获得时间
 * 字段 获得类型 type ||  0 表示转增，1表示购买
 * 字段 数字藏品编号 digital_collection_id 例如 1#5000 或 51#5000 等也就是id和总数进行拼接
```

detail_info: 存贮数字藏品的转移流程，用于追溯该藏品的转移全部流程

```
 * 主键 id
 * 字段 藏品hash
 * 字段 转移方用户地址 transfer_address
 * 字段 接受方用户地址 target_address
 * 字段 类型 type || 0 表示转增，1表示购买 ||用于藏品来源显示
 * 字段 更新时间  time
 * 字段 数字藏品编号 digital_collection_id 例如 1#5000 或 51#5000 等也就是id和总数进行拼接
```

 	nft_metas: 用于记录藏品的分类

```
* 主键 mid
* 字段 藏品分类名称 conllection_name
* 字段 藏品分类代号 conllection_slug
* 字段 该分类下藏品总数 count
```

nft_relationships: 用于记录藏品id和分类id的关系

```
* 字段 藏品id cid
* 字段 分类id mid
```

submit_cache：用户提交藏品审核表

.....更多数据表正在更新中，详情请看sql文件，如用户购买藏品是提交的订单表等