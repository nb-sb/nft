#### 系统架构设计

> 前言：此系统目前设计的是单机情况下，待系统代码全部写完后在出分布式情况下的设计，并做出相应的优化，目前单机系统下暂时不考虑redis，es等中简介宕机、断电等特殊情况(分布式系统的话就用集群、同步数据)。当然并不是作者不会分布式技术而是成熟的系统需要一步一步的优化(等这个系统完善后在出分布式版本)，上去就设计分布式不仅会增加工作量而且还会延期项目的交付，并不是一下就可以非常完美的，这里提醒各位同学没有谁的代码可以一步到位，都是经过不断优化的，欲速则不达

##### 1.支持高并发，解决高并发情况下的数据查询和写入的问题(查询藏品信息和超卖问题)

在数据查询的时候考虑到缓存和数据库进行双写、读写不一致，缓存穿透击穿等问题，详情看下方的 开发应考虑因素

##### 2.对api进行削峰填谷，优化api请求速度

![rabbitmq指定数据拉取请求](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/rabbitmq%E6%8C%87%E5%AE%9A%E6%95%B0%E6%8D%AE%E6%8B%89%E5%8F%96%E8%AF%B7%E6%B1%82.png)

###### 为什么要削峰？

防止在高峰时期占用大量的cpu等处理，导致服务器压力过高，从而出现宕机情况

普通下单业务流程

大量请求的时候可能会导致业务处理时间过长，mysql读写频率过高，导致机器宕机过卡顿等情况

![普通下单业务流程](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/%E6%99%AE%E9%80%9A%E4%B8%8B%E5%8D%95%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B.png)

使用mq下单业务流程

将业务处理的部分往后延申，防止大量的业务处理堆积在同一时间，从而达到消峰的目的

![mq消息](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/mq%E6%B6%88%E6%81%AF.png)



![订单状态修改](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/%E8%AE%A2%E5%8D%95%E7%8A%B6%E6%80%81%E4%BF%AE%E6%94%B9.png)

问：不是给我增加耗时吗？本来人家下订单本来可以直接进行操作数据库进行处理，你加了一个mq发送接受，不应该是增加了接口耗时吗？

答：如果在并发量不大的情况下，确实没问题，但是在高并发情况下如果不进行削锋很容易导致mysql连接或操作次数过多导致mysql宕机，你觉得是在并发量多的情况下老板是想让用户多等那不到`几毫秒`的时间还是说让mysql直接宕机？通常情况下，mq发送操作耗时几乎可以忽略不记，并且接受到信息进行执行也是异步执行的，整体来说会优化api请求速度

流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。

应用场景：

1.秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。	

2.任何需要异步的操作，可以优化接口相应速度

![异步注册操作](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/%E5%BC%82%E6%AD%A5%E6%B3%A8%E5%86%8C%E6%93%8D%E4%BD%9C.png)

##### 3.使用ES优化藏品搜索

​	ES的基本搜索使用例如关键词搜索，高亮搜索等。

##### 4.使用Redis缓存用户信息和热数据减少数据库压力

​	因为用户信息是固定的很少发生变化可以直接使用redis进行缓存避免每次都查询mysql数据库，同时使用redis进行缓存热数据，并考虑冷门藏品爆款等问题。

##### 5.对日志进行统一打印输出到文件中，使用异步线程优化日志

​	顾名思义使用log4j2优化日志输出至指定的文件夹中，日级别的分割日志方便管理，若大型系统还可以根据这个输出的日志进行做一个日志管理可视化查看或统计，更模块话的系统

![img](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/184329_a931b0a9_87650.png)

##### 6.订单表数量过多时解决方案，防止订单超过1000万以上数据，导致用户查询订单信息过慢

（案例：vivo 官方商城 订单模块是电商系统的交易核心，不断累积的数据即将达到单表存储瓶颈，系统难以支撑新品发布和大促活动期间的流量）

###### 1.吞吐量大的优化

吞吐量大的优化的解决方案有：

###### a 使用缓存

高并发架构的三板斧： 缓存、池化、异步

###### b 读写分离

主库负责执行数据更新请求，然后将数据变更实时同步到所有从库，用多个从库来分担查询请求。

###### c 分库分表

分库
分库又包含垂直分库和水平分库：

水平分库：把同一个表的数据按一定规则拆到不同的数据库中，每个库可以放在不同的服务器上；
垂直分库：按照业务将表进行分类，分布到不同的数据库上面，每个库可以放在不同的服务器上，它的核心理念是专库专用。
分库能够解决整体 高吞吐的问题

分表能够解决单表 高吞吐的问题

###### 2.高速搜索引擎的数据一致性优化

###### MQ方案

ES更新服务作为消费者，接收订单变更MQ消息后对ES进行更新

![img](%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BB%A3%E7%A0%81%E8%AE%BE%E8%AE%A1.assets/ad965b891a7ef7395c424e0553a49b72.jpeg)

其中BinLog方案比较通用，但实现起来也较为复杂，我们最终选用的是MQ方案。

因为ES数据只在管理后台使用，对数据可靠性和同步实时性的要求不是特别高。

考虑到宕机和消息丢失等极端情况，在后台增加了按某些条件手动同步ES数据的功能来进行补偿。

---

##### 开发应考虑因素 -- 后面给出解决办法，若有更多问题或更好解法欢迎讨论

压力因素：查询数据应先讲热数据保存至redis中，冷数据优先查询mysql后查询区块链中存贮、

数据因素：

  1. 缓存击穿问题，大量藏品在同一时间同时失效，大量请求穿过redis打到mysql中
     解决办法：添加redis缓存时增加随机数，防止缓存同一时间失效

  2. 缓存穿透问题，商品已经删了，但是大量的请求还是重复请求了redis然后redis查不到在查询mysql，导致数据库宕机，
     解决办法：可以设置空缓存，就是查询redis查不到，查询mysql差不到直接设置几分钟空缓存，下一个请求进来时只能查到redis中空值，不会导致数据库压力很大

  3. 突发性热点`缓存重建`导致系统压力暴增问题，比如十几万人同时点开这个冷门商品，刚开始同一时间可能会查询几万次mysql，而且有同时设置redis缓存 。解决办法使用synchronized、使用DCL(单例模式的双层检测锁) 也就是会从新查询一次redis数据库，不会导致在极端情况下，请求在等待synchronized排队后还的都重复查询mysql达不到设置缓存的效果，这里的synchronized不能锁this，不然比如说查2个商品的话，那就得都在这排队查询，很影响性能，比如多台机器每个机器都需要重构一次（这个影响很小），还有个问题就是如果这2个商品并没任何关系，所以不能锁this，比如锁商品id，但是如果是多台机器部署的后端还需要考虑很多问题,但是建议还是这里使用分布式redis锁，没想到吧！查询也需要使用redis锁不然也会导致mysql被打掉。

  4. 缓存与数据库双写不一致问题（缓存和数据库读写不一致也同理）：存在于在更新商品信息的时候正好有线程在查询这个商品，会导致缓存存贮的是旧信息
     解决方法：延时双删、设置缓存过期时间等，
     还有个`万全的`方法是继续使用分布式锁，在线程3查询数据库之前加锁和在线程2写入数据库之前加一把锁，这样就可以解决了
     问题：加那么多锁有性能问题，可以使用读写锁（读多写少）做性能优化，更新数据用写锁
     查询数据用读锁，这样读锁可以并发执行，而写锁会排队等待，这样可以优化性能
     	

应考虑mysql和区块链中数据一致性问题，例如数据更新时需要先更新区块链中数据在更新mysql中数据，考虑

业务因素：rabbitmq幂等性问题，比如创建一个mysql的流水表，在发送队列消息的时候插入到流水表中，下次插入时需要查询表中是否有记录，无记录才能插入，可以使用redis做记录不用mysql也可以

开发统一：数据库命名一律使用小写加下划线，禁止使用驼峰（linux和windows不同中有影响，详细请自查）

#### 代码优化更新记录

​	使用validation自定义等注解优化传入参数校验

#### 存贮设计

在mysql中：存贮用户基本信息

user_info：存贮用户基本信息 

```
*主键 id
*字段 用户地址 address
*字段 用户私钥 privatekey
*字段 用户名 username
*字段 用户密码 password
*字段 用户权限 role
*字段 用户余额 balance
```

user_detal：是否实名认证、认证信息

```
*主键 id
*字段 副主键和user_info对应的 外键
*字段 用户地址 address
*字段 身份证 cardid
*字段 手机号 phone_number
```

sell_info : 存贮发售信息

```
 * 主键 id
 * 字段 数字藏品 hash
 * 字段 发行量 amount
 * 字段 剩余数量 remain
 * 字段 数字藏品作者 auther
 * 字段 发售状态 status  # 1 为正常 ，  0 为闭售
```

owner_ship: 存贮当前用户的藏品所属权

```
 * 主键 id
 * 字段 用户地址 address
 * 字段 数字hash hash
 * 字段 获得时间
 * 字段 获得类型 type ||  0 表示转增，1表示购买
 * 字段 数字藏品编号 digital_collection_id 例如 1#5000 或 51#5000 等也就是id和总数进行拼接
```

detail_info: 存贮数字藏品的转移流程，用于追溯该藏品的转移全部流程

```
 * 主键 id
 * 字段 藏品hash
 * 字段 转移方用户地址 transfer_address
 * 字段 接受方用户地址 target_address
 * 字段 类型 type || 0 表示转增，1表示购买 ||用于藏品来源显示
 * 字段 更新时间  time
 * 字段 数字藏品编号 digital_collection_id 例如 1#5000 或 51#5000 等也就是id和总数进行拼接
```

 	nft_metas: 用于记录藏品的分类

```
* 主键 mid
* 字段 藏品分类名称 conllection_name
* 字段 藏品分类代号 conllection_slug
* 字段 该分类下藏品总数 count
```

nft_relationships: 用于记录藏品id和分类id的关系

```
* 字段 藏品id cid
* 字段 分类id mid
```

submit_cache：用户提交藏品审核表

.....更多数据表正在更新中，详情请看sql文件，如用户购买藏品是提交的订单表等